## Books

Model based machine learning: https://www.mbmlbook.com/

## AI / ML / DL tutorials

https://d2l.ai/index.html  Deep learning tutorial.

https://github.com/steven2358/awesome-generative-ai Various links related to Generative AI literature

https://www.promptingguide.ai/papers AI papers.

https://antoniolonga.github.io/Pytorch_geometric_tutorials/  Pytorch Geometric 

A few tutorials by Aman Chadha:

  https://aman.ai/primers/ai/gnn/
  
  https://aman.ai/recsys/gnn/
  
  https://aman.ai/primers/ai/transformers/
  
  https://aman.ai/primers/ai/bert/
  
  https://aman.ai/primers/ai/gpt/

## AI / ML / DL models

https://modelzoo.co/  Model Zoo - a collection of pre-trained DL models, preferable for transfer learning.

## LLM agents

https://github.com/WooooDyy/LLM-Agent-Paper-List

Practical deep learning: https://course.fast.ai/ (also check the video tutorial - https://www.youtube.com/watch?v=jkrNMKz9pWU&t=4s (LLM model tutorial))

## Lectures 

### AI

Efficient AI - MIT: https://www.youtube.com/playlist?list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB

Understanding deep learning: https://udlbook.github.io/udlbook/

Deep learning using Pytorch - Washington University - [Course Webpage](https://sites.wustl.edu/jeffheaton/t81-558/), [GitHub](https://github.com/jeffheaton/app_deep_learning) [Youtube](https://www.youtube.com/watch?v=r7eExQWKzdc&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi)




## ML / DL Seminal papers

### 2017

[Attention is all you need](https://arxiv.org/abs/1706.03762) - Transformer model from Google Brain

### 2018

[Graph Attention Networks](https://arxiv.org/abs/1710.10903) Concept of GAT. Uses binary edge connectivity (neighborhood) information, without edge features. Discusses the limitations of spectral approaches which uses graph laplacians (i.e. adjacency matrix representations and eigendecompostion, where the trained model heavily depends on the graph structure and cannot be applied on the graphs with different structure). Attention is useful since arbitrary neighborhood and graph structure (with different weights) can be supported, resulting in an inductive learning.



